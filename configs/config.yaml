
reasoner:
  mcts:
    exploration_weight: 1.414
    weight_scheduler: "exp"
    num_rollouts: 20 #default 20
    discount: 1.0
    verbose: False

agents:
  reason_agent:
    model: "meta-llama/Llama-3.2-1B-Instruct"
    base_url: "http://localhost:8000/v1"

  extract_agent:
    model: "meta-llama/Llama-3.2-1B-Instruct"
    base_url: "http://localhost:8001/v1"

  executor_agent:
    model: "meta-llama/Llama-3.2-1B-Instruct"
    base_url: "http://localhost:8000/v1"

  verifier_agent:
    model: "meta-llama/Llama-3.2-1B-Instruct"
    base_url: "http://localhost:8000/v1"

#for testing
#agent_endpoints:
#  reasoning:
#    model_name: meta-llama/Llama-3.2-1B-Instruct
#    endpoint: http://localhost:8000/v1
#  extraction:
#    model_name: meta-llama/Llama-3.2-1B-Instruct
#    endpoint: http://localhost:8001/v1
#  calculation:
#    model_name: meta-llama/Llama-3.2-1B-Instruct
#    endpoint: http://localhost:8002/v1
#  tool:
#    model_name: meta-llama/Llama-3.2-1B-Instruct
#    endpoint: http://localhost:8003/v1
#  verify:
#    model_name: meta-llama/Meta-Llama-3-8B-Instruct
#    endpoint: http://localhost:8004/v1

#for deploying
#agent_endpoints:
#  reasoning:
#    model_name: meta-llama/Meta-Llama-3-8B-Instruct
#    endpoint: http://localhost:8000/v1
#  extraction:
#    model_name: meta-llama/Meta-Llama-3-8B-Instruct
#    endpoint: http://localhost:8001/v1
#  calculation:
#    model_name: meta-llama/Meta-Llama-3-8B-Instruct
#    endpoint: http://localhost:8002/v1
#  tool:
#    model_name: meta-llama/Meta-Llama-3-8B-Instruct
#    endpoint: http://localhost:8003/v1
#  verify:
#    model_name: meta-llama/Meta-Llama-3-8B-Instruct
#    endpoint: http://localhost:8004/v1

logging:
  level: INFO
  file: logs/app.log